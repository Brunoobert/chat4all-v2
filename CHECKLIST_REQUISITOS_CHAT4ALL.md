# Checklist de Requisitos - Chat4All v2
## Objetivo: Atender 100% dos requisitos funcionais e n√£o funcionais

---

## üìã 2. REQUISITOS FUNCIONAIS

### 2.1 Mensageria B√°sica

#### ‚úÖ Criar/Entrar em Conversas
- [] **RF-2.1.1**: Implementar `POST /v1/conversations` para criar conversas privadas (1:1)
  - Body: `{ "type": "private", "members": ["userA", "userB"], "metadata": {} }`
  - Validar que ambos os usu√°rios existem (via metadata_service)
  - Criar registro em Cassandra ou CockroachDB com `conversation_id`, `type`, `members`, `created_at`
  - Retornar `{ "conversation_id": "<uuid>", "type": "private", ... }`

- [ ] **RF-2.1.2**: Implementar `POST /v1/conversations` para criar grupos (n membros)
  - Body: `{ "type": "group", "members": ["userA", "userB", "userC", ...], "metadata": {"name": "..."} }`
  - Validar que todos os membros existem
  - Criar registro de grupo com lista de membros
  - Retornar `conversation_id` do grupo

- [ ] **RF-2.1.3**: Implementar `GET /v1/conversations` para listar conversas do usu√°rio autenticado
  - Filtrar por `conversation_id` onde o usu√°rio est√° em `members`
  - Retornar lista com metadados (√∫ltima mensagem, timestamp, etc.)

- [] **RF-2.1.4**: Criar tabela/modelo de `conversations` em Cassandra ou CockroachDB
  - Campos: `conversation_id` (PK), `type` (private/group), `members` (list), `created_at`, `metadata` (map)

#### ‚úÖ Envio de Mensagens
- [x] **RF-2.1.5**: `POST /v1/messages` j√° implementado (‚úÖ OK)
- [ ] **RF-2.1.6**: Validar que `conversation_id` existe e usu√°rio autenticado √© membro antes de enviar
- [ ] **RF-2.1.7**: Suportar envio para m√∫ltiplos destinat√°rios em grupos (campo `to` pode ser lista)

#### ‚úÖ Envio de Arquivos at√© 2GB
- [x] **RF-2.1.8**: Upload b√°sico para MinIO j√° existe (‚úÖ OK)
- [x] **RF-2.1.9**: Implementar **chunked upload resumable** (protocolo tipo tus ou S3 multipart) (‚ö†Ô∏è PARCIAL)
  - `POST /v1/files/initiate` ‚Üí retorna `upload_url` (presigned), `file_id`, `chunk_size` - ‚úÖ Implementado
  - `PATCH /v1/files/{file_id}/chunk` ‚Üí upload de chunk individual (com offset) - ‚ùå Falta implementar
  - `POST /v1/files/{file_id}/complete` ‚Üí finaliza upload com checksum - ‚ùå Falta implementar
  - Armazenar manifest de chunks no DB (metadados: `file_id`, `total_size`, `chunks[]`, `checksum`) - ‚ö†Ô∏è Parcial

- [ ] **RF-2.1.10**: Validar tamanho m√°ximo de 2GB no endpoint de initiate
- [ ] **RF-2.1.11**: Implementar l√≥gica de resume (verificar chunks j√° enviados e continuar)

#### ‚úÖ Recep√ß√£o em Tempo Real / Entrega Retardada
- [x] **RF-2.1.12**: Implementar **WebSocket endpoint** para clientes internos conectados (‚úÖ OK)
  - `WS /ws` com autentica√ß√£o via token - ‚úÖ Implementado
  - Enviar mensagens em tempo real quando destinat√°rio est√° online - ‚úÖ Implementado via Redis
  - Manter conex√£o ativa e heartbeat - ‚úÖ Implementado

- [ ] **RF-2.1.13**: Implementar **Presence Service** (rastreia quem est√° online)
  - Endpoint: `POST /v1/presence/heartbeat` (chamado periodicamente pelo cliente)
  - Armazenar em cache (Redis) ou DB: `user_id` ‚Üí `last_seen`, `status` (online/offline)
  - Endpoint: `GET /v1/presence/{user_id}` para consultar status

- [x] **RF-2.1.14**: Implementar l√≥gica de **store-and-forward** no router_worker (‚úÖ PARCIAL)
  - Se destinat√°rio est√° offline ‚Üí persistir em Cassandra (‚úÖ j√° faz)
  - Se destinat√°rio est√° online ‚Üí enviar via WebSocket (‚úÖ implementado via Redis)
  - Quando usu√°rio volta online, consultar mensagens pendentes e entregar - ‚ö†Ô∏è Falta l√≥gica de consulta de pendentes

---

### 2.2 Controle de Envio / Entrega / Leitura

#### ‚úÖ Estados de Mensagem
- [x] **RF-2.2.1**: Estados SENT/DELIVERED/READ j√° implementados (‚úÖ OK)
- [ ] **RF-2.2.2**: Criar **tabela de hist√≥rico de estados** (n√£o apenas campo √∫nico)
  - Tabela: `message_status_history` com campos: `message_id`, `status`, `timestamp`, `source`
  - Registrar cada transi√ß√£o: SENT ‚Üí DELIVERED ‚Üí READ

- [ ] **RF-2.2.3**: Implementar `GET /v1/messages/{message_id}/status/history`
  - Retornar array de estados com timestamps: `[{ "status": "SENT", "timestamp": "...", ... }, ...]`

- [ ] **RF-2.2.4**: Implementar **idempot√™ncia e deduplica√ß√£o**
  - No `router_worker`, antes de inserir em Cassandra, verificar se `message_id` j√° existe
  - Usar `INSERT IF NOT EXISTS` ou `SELECT` antes de `INSERT` em Cassandra
  - Se duplicado detectado, logar e pular processamento

- [ ] **RF-2.2.5**: Aceitar `message_id` fornecido pelo cliente (UUIDv4) ou gerar se n√£o fornecido
  - Validar formato UUID no frontend_service antes de enviar ao Kafka

- [ ] **RF-2.2.6**: Implementar confirma√ß√£o de entrega/leitura solicit√°vel pelo remetente
  - Adicionar campo opcional `request_delivery_receipt: bool` no `MessageIn`
  - Se `true`, garantir que callbacks sejam enviados quando DELIVERED/READ

---

### 2.3 Multiplataforma e Roteamento por Canal

#### ‚úÖ Sele√ß√£o de Canais
- [x] **RF-2.3.1**: Modificar `POST /v1/messages` para aceitar campo `channels` (‚úÖ OK)
  - Body aceita: `"channels": ["whatsapp", "instagram"]` ou `"channels": ["all"]` - ‚úÖ Schema implementado
  - Validar que canais s√£o suportados (lista de canais dispon√≠veis) - ‚ö†Ô∏è Falta valida√ß√£o

- [ ] **RF-2.3.2**: Modificar `router_worker` para rotear baseado em `channels` (n√£o heur√≠stica de `@`)
  - Ler campo `channels` do payload Kafka - ‚ö†Ô∏è Campo existe no schema, mas roteamento ainda usa heur√≠stica
  - Se `["all"]` ‚Üí enviar para todos os t√≥picos de connectors dispon√≠veis
  - Se lista espec√≠fica ‚Üí enviar apenas para t√≥picos correspondentes (`whatsapp_outbound`, `instagram_outbound`, etc.)

- [ ] **RF-2.3.3**: Criar **mapeamento de usu√°rios entre plataformas** (Metadata Service)
  - Tabela: `user_channels` com campos: `user_id`, `channel_type` (whatsapp/instagram/telegram), `channel_identifier` (phone/@handle), `is_active`
  - Endpoint: `POST /v1/users/{user_id}/channels` para vincular canais
  - Endpoint: `GET /v1/users/{user_id}/channels` para listar canais do usu√°rio

- [ ] **RF-2.3.4**: Implementar roteamento cross-channel inteligente
  - Quando mensagem chega de WhatsApp para usu√°rio X, verificar canais de X
  - Se X tem Instagram configurado, enviar tamb√©m para Instagram
  - Permitir que usu√°rio WhatsApp envie mensagem que chegue ao Direct do Instagram de outro usu√°rio

- [ ] **RF-2.3.5**: Criar **registry de connectors dispon√≠veis**
  - Arquivo/config: lista de connectors ativos e seus t√≥picos Kafka
  - Exemplo: `{"whatsapp": "whatsapp_outbound", "instagram": "instagram_outbound", "telegram": "telegram_outbound"}`

---

### 2.4 Persist√™ncia

#### ‚úÖ Armazenamento de Mensagens
- [x] **RF-2.4.1**: Persist√™ncia em Cassandra j√° implementada (‚úÖ OK)
- [ ] **RF-2.4.2**: Adicionar TTL configur√°vel para mensagens antigas (opcional, conforme PDF)
  - Configurar TTL na tabela `messages` do Cassandra (ex.: 1 ano)

#### ‚úÖ Armazenamento de Arquivos
- [x] **RF-2.4.3**: MinIO j√° configurado (‚úÖ OK)
- [ ] **RF-2.4.4**: Criar tabela de metadados de arquivos em Cassandra/CockroachDB
  - Campos: `file_id`, `filename`, `content_type`, `size`, `checksum`, `chunk_manifest` (JSON), `upload_status`, `created_at`, `download_url`
  - Relacionar `file_id` com mensagens na tabela `messages`

- [ ] **RF-2.4.5**: Implementar endpoint `GET /v1/files/{file_id}` para download
  - Retornar presigned URL ou stream direto do MinIO
  - Validar permiss√µes (usu√°rio tem acesso √† conversa que cont√©m o arquivo)

---

### 2.5 API P√∫blica e SDKs

#### ‚úÖ Endpoints REST/gRPC
- [x] **RF-2.5.1**: Endpoints b√°sicos j√° implementados (‚úÖ OK)
- [ ] **RF-2.5.2**: Implementar `POST /v1/webhooks` para registro de webhooks
  - Body: `{ "url": "https://...", "events": ["message.delivered", "message.read"], "secret": "..." }`
  - Armazenar em CockroachDB: tabela `webhooks` com `user_id`, `url`, `events[]`, `secret`, `is_active`
  - Validar URL e secret antes de salvar

- [ ] **RF-2.5.3**: Implementar disparo de webhooks quando eventos ocorrem
  - No `router_worker` ou connectors, quando status muda para DELIVERED/READ:
    - Consultar webhooks registrados para o usu√°rio remetente
    - Filtrar por eventos (`message.delivered`, `message.read`)
    - Fazer POST HTTP para cada webhook com payload: `{ "message_id": "...", "status": "...", "timestamp": "..." }`
    - Assinar payload com HMAC usando `secret` do webhook

- [ ] **RF-2.5.4**: Implementar retry exponencial para webhooks falhos
  - Se webhook falha (timeout/5xx), reenfileirar com backoff
  - M√°ximo de 3 tentativas

- [ ] **RF-2.5.5**: Gerar documenta√ß√£o OpenAPI/Swagger completa
  - FastAPI j√° gera `/docs`, mas adicionar:
    - Descri√ß√µes detalhadas de cada endpoint
    - Exemplos de request/response
    - C√≥digos de erro poss√≠veis
    - Exportar para arquivo `openapi.json` e versionar

- [ ] **RF-2.5.6**: Criar SDK Python b√°sico
  - Classe `Chat4AllClient` com m√©todos: `send_message()`, `get_conversations()`, `upload_file()`, `register_webhook()`
  - Publicar em PyPI ou disponibilizar como pacote local

- [ ] **RF-2.5.7**: Criar SDK JavaScript/TypeScript b√°sico (opcional, mas recomendado)
  - Similar ao Python, para uso em frontend web

---

### 2.6 Extensibilidade de Canais

#### ‚úÖ Interface Padronizada para Adapters
- [ ] **RF-2.6.1**: Criar **interface/contrato formal** para connectors
  - Documentar: `connect()`, `sendMessage(dest, payload)`, `sendFile(dest, fileReference)`, `onWebhookEvent(event)`
  - Criar classe base abstrata ou protocolo (Python `Protocol` ou ABC)

- [ ] **RF-2.6.2**: Refatorar connectors existentes para seguir a interface
  - `connector_whatsapp` e `connector_instagram` devem implementar m√©todos padronizados
  - Padronizar formato de payload Kafka de entrada

- [ ] **RF-2.6.3**: Criar **documenta√ß√£o para desenvolver novos connectors**
  - README em `services/connector_template/` com:
    - Estrutura de projeto
    - Como consumir t√≥pico Kafka
    - Como enviar callbacks de status
    - Exemplo m√≠nimo funcional

- [ ] **RF-2.6.4**: Criar template/boilerplate de connector
  - Pasta `services/connector_template/` com c√≥digo exemplo comentado
  - Dockerfile e requirements.txt de exemplo

---

## üìã 3. REQUISITOS N√ÉO FUNCIONAIS (NFR)

### 3.1 Escalabilidade

- [ ] **NFR-3.1.1**: Configurar **m√∫ltiplos brokers Kafka** no docker-compose
  - Adicionar `kafka-2`, `kafka-3` com `KAFKA_BROKER_ID` diferentes
  - Configurar replica√ß√£o de t√≥picos (ex.: `replication-factor: 3`)

- [ ] **NFR-3.1.2**: Configurar **cluster Cassandra** (m√∫ltiplos n√≥s)
  - Adicionar `cassandra-2`, `cassandra-3` no docker-compose
  - Configurar seeds e replication factor

- [ ] **NFR-3.1.3**: Configurar **m√∫ltiplas inst√¢ncias de workers** (horizontal scaling)
  - No docker-compose, usar `deploy.replicas: 3` ou m√∫ltiplos servi√ßos `router_worker_1`, `router_worker_2`, etc.
  - Garantir que particionamento Kafka distribui carga entre workers

- [ ] **NFR-3.1.4**: Implementar **sharding din√¢mico por conversation_id**
  - Particionar mensagens por `conversation_id` hash
  - Documentar estrat√©gia de re-sharding sem downtime (se necess√°rio)

- [ ] **NFR-3.1.5**: Criar **testes de carga** documentados
  - Usar `locustfile.py` existente ou criar scripts K6/Gatling
  - Testar: 100k mensagens/min (ajustar conforme escopo do curso)
  - Documentar resultados: throughput alcan√ßado, lat√™ncia p50/p95/p99

- [ ] **NFR-3.1.6**: Demonstrar **escalabilidade horizontal** em execu√ß√£o
  - Adicionar n√≥s em tempo de execu√ß√£o e mostrar aumento de capacidade
  - Documentar com screenshots/m√©tricas

---

### 3.2 Alta Disponibilidade / Toler√¢ncia a Falhas

- [ ] **NFR-3.2.1**: Configurar **replica√ß√£o Kafka** (j√° mencionado em 3.1.1)
  - T√≥picos com `replication-factor >= 2`
  - Configurar `min.insync.replicas`

- [ ] **NFR-3.2.2**: Configurar **replica√ß√£o Cassandra** (j√° mencionado em 3.1.2)
  - Replication factor >= 3 para keyspace `chat4all_ks`
  - Configurar consistency level adequado (QUORUM para leitura/escrita)

- [ ] **NFR-3.2.3**: Implementar **health checks robustos** em todos os servi√ßos
  - Endpoint `/health` que verifica depend√™ncias (Kafka, DB, MinIO)
  - Retornar `200` apenas se todas as depend√™ncias est√£o OK
  - Usar em `docker-compose` com `healthcheck`

- [ ] **NFR-3.2.4**: Implementar **circuit breaker** nos connectors
  - Se connector externo (WhatsApp/Instagram API) falha repetidamente, abrir circuit
  - Parar de enviar mensagens temporariamente e retomar ap√≥s timeout
  - Usar biblioteca como `circuitbreaker` (Python)

- [ ] **NFR-3.2.5**: Implementar **retry com backoff exponencial** em pontos cr√≠ticos
  - No `router_worker`, se falha ao salvar em Cassandra, retry com backoff
  - No envio de webhooks, retry com backoff (j√° mencionado em RF-2.5.4)

- [ ] **NFR-3.2.6**: Criar **testes de failover** documentados
  - Cen√°rio: derrubar n√≥ Kafka, n√≥ Cassandra, worker
  - Demonstrar que sistema continua funcionando (com degrada√ß√£o aceit√°vel)
  - Documentar perda de mensagens (se houver) e tempo de recupera√ß√£o

- [ ] **NFR-3.2.7**: Configurar **monitoramento de SLA** (99.95%)
  - Alertas no Prometheus/Alertmanager quando uptime < 99.95%
  - Dashboard no Grafana mostrando uptime por servi√ßo

---

### 3.3 Consist√™ncia & Garantias de Entrega

- [ ] **NFR-3.3.1**: Implementar **deduplica√ß√£o robusta** (j√° mencionado em RF-2.2.4)
  - Usar `message_id` como chave √∫nica em Cassandra (com `IF NOT EXISTS`)
  - Ou usar tabela separada `processed_messages` para tracking

- [ ] **NFR-3.3.2**: Garantir **ordem causal por conversa**
  - ‚úÖ J√° implementado via `key=str(chat_id)` no Kafka (OK)
  - Validar que m√∫ltiplos workers respeitam ordem (usar mesmo consumer group)

- [ ] **NFR-3.3.3**: Documentar estrat√©gia de **at-least-once vs effectively-once**
  - Documentar que sistema garante at-least-once com deduplica√ß√£o
  - Explicar trade-offs e quando effectively-once seria necess√°rio

- [ ] **NFR-3.3.4**: Implementar **idempotent writes** em Cassandra
  - Usar `INSERT ... IF NOT EXISTS` ou `UPDATE` condicional
  - Garantir que m√∫ltiplas tentativas n√£o criam duplicatas

---

### 3.4 Lat√™ncia

- [ ] **NFR-3.4.1**: Medir e documentar **lat√™ncia end-to-end**
  - Cliente ‚Üí Frontend ‚Üí Kafka ‚Üí Worker ‚Üí DB
  - Objetivo: < 200ms para caminhos internos
  - Usar tracing distribu√≠do (OpenTelemetry) para identificar gargalos

- [ ] **NFR-3.4.2**: Otimizar queries Cassandra
  - Criar √≠ndices secund√°rios se necess√°rio
  - Evitar queries que fazem full scan

- [ ] **NFR-3.4.3**: Implementar **caching** onde apropriado
  - Cache de presen√ßa de usu√°rios (Redis)
  - Cache de metadados de conversas (opcional)

---

### 3.5 Throughput

- [ ] **NFR-3.5.1**: Projetar para **milhares de mensagens/s por n√≥**
  - Testar throughput de um worker isolado
  - Documentar capacidade m√°xima por inst√¢ncia

- [ ] **NFR-3.5.2**: Implementar **particionamento eficiente** no Kafka
  - Aumentar n√∫mero de parti√ß√µes do t√≥pico `chat_messages` conforme necessidade
  - Garantir que particionamento por `conversation_id` distribui carga uniformemente

- [ ] **NFR-3.5.3**: Otimizar **batch processing** no worker
  - Processar m√∫ltiplas mensagens em batch quando poss√≠vel
  - Configurar `batch_size` no Kafka consumer

---

### 3.6 Armazenamento de Arquivos (2GB, Chunked/Resume)

- [ ] **NFR-3.6.1**: Implementar **chunked upload** (j√° mencionado em RF-2.1.9)
  - Protocolo resumable (tus ou S3 multipart)
  - Suportar arquivos at√© 2GB

- [ ] **NFR-3.6.2**: Implementar **resume de upload** interrompido
  - Endpoint `GET /v1/files/{file_id}/status` retorna chunks j√° enviados
  - Cliente pode continuar de onde parou

- [ ] **NFR-3.6.3**: Validar **checksum** ap√≥s upload completo
  - Calcular MD5/SHA256 do arquivo completo
  - Comparar com checksum fornecido pelo cliente
  - Rejeitar se n√£o corresponder

- [ ] **NFR-3.6.4**: Implementar **estrat√©gia de replica√ß√£o** no MinIO (opcional)
  - Configurar MinIO em modo distribu√≠do com m√∫ltiplos n√≥s
  - Ou documentar que MinIO √© single-node para PoC

---

### 3.7 Observabilidade

#### ‚úÖ Prometheus & Grafana
- [x] **NFR-3.7.1**: Prometheus e Grafana j√° configurados (‚úÖ OK)
- [ ] **NFR-3.7.2**: Adicionar **m√©tricas customizadas** em todos os servi√ßos
  - `frontend_service`: j√° tem m√©tricas HTTP (‚úÖ OK)
  - `router_worker`: j√° tem `MESSAGES_PROCESSED` (‚úÖ OK)
  - Adicionar: lat√™ncia de processamento, taxa de erro por connector, utiliza√ß√£o de disco

- [ ] **NFR-3.7.3**: Criar **dashboards Grafana** completos
  - Dashboard: Throughput de mensagens (msg/s)
  - Dashboard: Lat√™ncia de entrega (p50/p95/p99)
  - Dashboard: Taxa de erro por servi√ßo
  - Dashboard: Utiliza√ß√£o de recursos (CPU, mem√≥ria, disco)
  - Exportar dashboards como JSON e versionar

#### ‚úÖ Tracing Distribu√≠do
- [ ] **NFR-3.7.4**: Implementar **OpenTelemetry** em todos os servi√ßos
  - Instrumentar `frontend_service`, `router_worker`, connectors
  - Criar spans para cada opera√ß√£o cr√≠tica (envio de mensagem, processamento, entrega)
  - Configurar exportador para Jaeger ou Zipkin

- [ ] **NFR-3.7.5**: Adicionar **trace_id** e **span_id** nos logs
  - Correlacionar logs com traces
  - Usar formato estruturado (JSON) nos logs

#### ‚úÖ Logs Estruturados
- [ ] **NFR-3.7.6**: Configurar **stack de logging centralizado** (ELK/EFK)
  - Adicionar Elasticsearch e Logstash/Fluentd no docker-compose
  - Ou usar Loki (mais leve) como alternativa
  - Configurar todos os servi√ßos para enviar logs para stack centralizada

- [ ] **NFR-3.7.7**: Padronizar **formato de logs** (JSON estruturado)
  - Todos os servi√ßos devem logar em JSON com campos: `timestamp`, `level`, `service`, `message`, `trace_id`, `message_id`

- [ ] **NFR-3.7.8**: Criar **dashboards de logs** no Grafana/Kibana
  - Visualizar logs por servi√ßo, n√≠vel, trace_id
  - Filtrar por erro, warning, etc.

#### ‚úÖ M√©tricas Chave
- [ ] **NFR-3.7.9**: Implementar m√©tricas espec√≠ficas mencionadas no PDF:
  - ‚úÖ Mensagens/s (j√° implementado parcialmente)
  - [ ] Lat√™ncia de entrega (adicionar histograma no worker)
  - [ ] Taxa de erro connectors (adicionar counter por connector)
  - [ ] Utiliza√ß√£o de disco (usar node_exporter)
  - [ ] Throughput de object storage (adicionar m√©tricas no MinIO ou proxy)

---

### 3.9 Extensibilidade / Manutenibilidade

- [x] **NFR-3.9.1**: Versionamento de API j√° implementado (`/v1/...`) (‚úÖ OK)
- [ ] **NFR-3.9.2**: Criar **interface clean para adapters** (j√° mencionado em RF-2.6.1)
- [ ] **NFR-3.9.3**: Documentar **arquitetura** em README.md principal
  - Diagrama de componentes
  - Fluxo de mensagens (cliente ‚Üí API ‚Üí Kafka ‚Üí Worker ‚Üí Connectors)
  - Decis√µes t√©cnicas (por que Kafka, Cassandra, etc.)

- [ ] **NFR-3.9.4**: Criar **guia de desenvolvimento** (DEVELOPMENT.md)
  - Como rodar localmente
  - Como adicionar novo connector
  - Como adicionar novo endpoint
  - Conven√ß√µes de c√≥digo

- [ ] **NFR-3.9.5**: Adicionar **testes unit√°rios** para componentes cr√≠ticos
  - Testes para `router_worker` (l√≥gica de roteamento)
  - Testes para `frontend_service` (valida√ß√µes, autentica√ß√£o)
  - Usar pytest ou similar

- [ ] **NFR-3.9.6**: Adicionar **testes de integra√ß√£o** end-to-end
  - Teste completo: criar conversa ‚Üí enviar mensagem ‚Üí verificar entrega ‚Üí verificar status READ
  - Usar pytest com fixtures para subir servi√ßos via docker-compose

---

## üìã 4. ARQUITETURA PROPOSTA (Valida√ß√£o)

### Componentes Principais

- [x] **ARQ-1**: API Gateway / Ingress (stateless) - ‚úÖ FastAPI stateless (OK)
- [x] **ARQ-2**: Frontend Service (Stateless) - ‚úÖ Implementado (OK)
- [x] **ARQ-3**: Message Broker (Kafka) - ‚úÖ Implementado (OK)
- [x] **ARQ-4**: Workers / Router Services - ‚úÖ Implementado (OK)
- [x] **ARQ-5**: Connectors / Channel Adapters - ‚úÖ Implementado (2 mocks) (OK)
- [x] **ARQ-6**: Metadata DB (CockroachDB) - ‚úÖ Implementado (OK)
- [x] **ARQ-7**: Message Store (Cassandra) - ‚úÖ Implementado (OK)
- [x] **ARQ-8**: Object Storage (MinIO) - ‚úÖ Implementado (OK)
- [x] **ARQ-9**: Notification / Push Service - ‚úÖ Implementado (WebSocket + Redis)
- [ ] **ARQ-10**: Presence Service - ‚ö†Ô∏è N√£o implementado (falta endpoints de heartbeat)
- [x] **ARQ-11**: Admin & Monitoring (Prometheus/Grafana) - ‚úÖ Implementado (OK)

---

## üìã 5. DECIS√ïES T√âCNICAS (Valida√ß√£o)

- [x] **TEC-1**: Apache Kafka como backbone - ‚úÖ OK
- [x] **TEC-2**: Particionamento por conversation_id - ‚úÖ OK (via key)
- [x] **TEC-3**: MongoDB/Cassandra para mensagens - ‚úÖ Cassandra OK
- [ ] **TEC-4**: Estrat√©gia de replica√ß√£o MinIO - ‚ö†Ô∏è Single-node apenas
- [x] **TEC-5**: Connectors como servi√ßos independentes - ‚úÖ OK
- [ ] **TEC-6**: Idempot√™ncia e deduplica√ß√£o - ‚ö†Ô∏è Parcial (faltam checagens)
- [x] **TEC-7**: Observability (Prometheus) - ‚úÖ Parcial (faltam tracing e logs centralizados)

---

## üìã 6. API P√öBLICA (Valida√ß√£o de Endpoints)

### 6.1 Autentica√ß√£o
- [x] **API-1**: `POST /auth/token` - ‚úÖ Implementado como `/token` (OK)

### 6.2 Conversas
- [ ] **API-2**: `POST /v1/conversations` - ‚ö†Ô∏è N√£o implementado
- [x] **API-3**: `GET /v1/conversations/{conversation_id}/messages` - ‚úÖ Implementado (OK)

### 6.3 Enviar Mensagem
- [x] **API-4**: `POST /v1/messages` - ‚úÖ Implementado (OK)
- [ ] **API-5**: Suportar campo `channels` no body - ‚ö†Ô∏è N√£o implementado

### 6.4 Upload de Arquivo (Resumable)
- [ ] **API-6**: `POST /v1/files/initiate` - ‚ö†Ô∏è N√£o implementado
- [ ] **API-7**: `PATCH/PUT` upload chunks - ‚ö†Ô∏è N√£o implementado
- [ ] **API-8**: `POST /v1/files/complete` - ‚ö†Ô∏è N√£o implementado
- [x] **API-9**: Upload simples existe - ‚úÖ Mas n√£o √© resumable

### 6.5 Delivery / Read Callbacks (Webhooks)
- [ ] **API-10**: `POST /v1/webhooks` - ‚ö†Ô∏è N√£o implementado
- [ ] **API-11**: Callback payloads com message_id e status - ‚ö†Ô∏è Parcial (callbacks existem, mas n√£o s√£o configur√°veis)

---

## üìã 7. REQUISITOS DE TESTE / VALIDA√á√ÉO

- [ ] **TEST-1**: **Teste de carga** documentado
  - Usar k6, Gatling ou Locust
  - Alvo: 100k msgs/min (ajustar conforme escopo)
  - Documentar resultados: throughput, lat√™ncia, erros

- [ ] **TEST-2**: **Testes de falhas controladas**
  - Derrubar n√≥ Kafka ‚Üí demonstrar failover
  - Derrubar n√≥ Cassandra ‚Üí demonstrar recupera√ß√£o
  - Derrubar worker ‚Üí demonstrar rebalancing
  - Documentar perda de mensagens (se houver)

- [ ] **TEST-3**: **Teste cross-channel**
  - Enviar de WhatsApp para Instagram Direct
  - Demonstrar transi√ß√£o e callbacks
  - Documentar com screenshots/logs

- [ ] **TEST-4**: **Teste de upload/download de arquivos grandes**
  - Enviar arquivo ~1.8GB
  - Demonstrar chunking/resume
  - Validar checksum

- [ ] **TEST-5**: **Teste de escalabilidade horizontal**
  - Adicionar n√≥s em tempo de execu√ß√£o
  - Mostrar aumento de capacidade
  - Documentar com m√©tricas

- [ ] **TEST-6**: **Demonstra√ß√£o de observabilidade**
  - Dashboards mostrando m√©tricas
  - Tracing de fluxo de mensagens
  - Logs correlacionados

---

## üìã 8. ENTREG√ÅVEIS FINAIS

- [x] **ENT-1**: C√≥digo-fonte com README - ‚úÖ OK
- [ ] **ENT-2**: Scripts de deploy (K8s manifests ou docker-compose) - ‚ö†Ô∏è docker-compose existe, mas falta K8s (opcional)
- [ ] **ENT-3**: Documenta√ß√£o da API (OpenAPI) - ‚ö†Ô∏è FastAPI gera, mas falta exportar e versionar
- [ ] **ENT-4**: Relat√≥rio t√©cnico (m√°x 15 p√°ginas) - ‚ö†Ô∏è N√£o verificado
- [ ] **ENT-5**: Script/instru√ß√µes para demo - ‚ö†Ô∏è N√£o verificado
  - Cen√°rio b√°sico (chat interno)
  - Cen√°rio cross-platform (WhatsApp ‚Üí Instagram)
  - Cen√°rio de stress
- [ ] **ENT-6**: Dashboards e logs de execu√ß√£o - ‚ö†Ô∏è Dashboards Grafana precisam ser criados
- [ ] **ENT-7**: V√≠deo curto da demonstra√ß√£o (opcional) - ‚ö†Ô∏è N√£o verificado

---

## üìä RESUMO DE STATUS

### Requisitos Funcionais
- ‚úÖ **Implementados**: ~40%
- ‚ö†Ô∏è **Parciais**: ~35%
- ‚ùå **N√£o implementados**: ~25%

### Requisitos N√£o Funcionais
- ‚úÖ **Implementados**: ~30%
- ‚ö†Ô∏è **Parciais**: ~40%
- ‚ùå **N√£o implementados**: ~30%

### Prioriza√ß√£o Sugerida

#### üî¥ **ALTA PRIORIDADE** (Cr√≠ticos para funcionalidade b√°sica)
1. RF-2.1.1 a RF-2.1.3: Criar/gerenciar conversas
2. RF-2.2.4: Idempot√™ncia e deduplica√ß√£o
3. RF-2.3.1 a RF-2.3.2: Sele√ß√£o de canais pelo cliente
4. RF-2.1.9 a RF-2.1.11: Chunked upload resumable (2GB)
5. RF-2.5.2 a RF-2.5.4: Webhooks configur√°veis

#### üü° **M√âDIA PRIORIDADE** (Importantes para completude)
6. RF-2.1.12 a RF-2.1.14: WebSocket e Presence Service
7. RF-2.2.2 a RF-2.2.3: Hist√≥rico de estados
8. RF-2.3.3 a RF-2.3.4: Mapeamento de usu√°rios entre plataformas
9. NFR-3.7.4: OpenTelemetry tracing
10. NFR-3.7.6: Logs centralizados (ELK/Loki)

#### üü¢ **BAIXA PRIORIDADE** (Melhorias e polish)
11. RF-2.5.6 a RF-2.5.7: SDKs Python/JS
12. RF-2.6.1 a RF-2.6.4: Interface formal para connectors
13. NFR-3.1.1 a NFR-3.1.3: M√∫ltiplos n√≥s (escalabilidade real)
14. NFR-3.2.1 a NFR-3.2.7: Alta disponibilidade completa
15. TEST-1 a TEST-6: Testes de valida√ß√£o documentados

---

## üìù NOTAS FINAIS

- Este checklist √© baseado na an√°lise do c√≥digo atual e do documento `chat4all v2.pdf`
- Itens marcados com ‚úÖ j√° est√£o implementados
- Itens marcados com ‚ö†Ô∏è est√£o parcialmente implementados
- Itens marcados com ‚ùå n√£o est√£o implementados
- Priorize os itens de ALTA PRIORIDADE para atingir funcionalidade b√°sica completa
- Use este checklist como guia de desenvolvimento e valida√ß√£o final

---

**√öltima atualiza√ß√£o**: Baseado na an√°lise do c√≥digo em `frontend_service/`, `services/`, `docker-compose.yml` e requisitos do PDF.



